{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import pandas as pd\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_xpath(xpath):\n",
    "    xpath = str(xpath).replace('[\"','').replace('\"]','')\n",
    "    xpath = str(xpath).replace(\"['\",\"\").replace(\"']\",\"\")\n",
    "    return xpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proxy_list():\n",
    "    url = 'https://www.proxynova.com/proxy-server-list/country-in/'\n",
    "    page = requests.get(url)\n",
    "    tree = html.fromstring(page.content)\n",
    "    proxy_list = tree.xpath('//abbr')\n",
    "    proxy = []\n",
    "    for i in proxy_list:\n",
    "        p = i.get('title')\n",
    "        if len(p)<16:\n",
    "            proxy.append(p)\n",
    "    return proxy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(news_url, proxy):\n",
    "    page = requests.get(news_url, proxies=proxy)\n",
    "    tree = html.fromstring(page.content)\n",
    "    headline = clean_xpath(tree.xpath(\"/html/body/div[4]/div/div[3]/div/div/div[2]/a/span/text()\"))\n",
    "    author = clean_xpath(tree.xpath(\"/html/body/div[4]/div/div[3]/div/div/div[2]/div/span[1]/text()\"))\n",
    "    time = clean_xpath(tree.xpath(\"/html/body/div[4]/div/div[3]/div/div/div[2]/div/span[2]/text()\"))\n",
    "    date = clean_xpath(tree.xpath(\"/html/body/div[4]/div/div[3]/div/div/div[2]/div/span[3]/text()\"))\n",
    "    date = \"-\".join(date.split(\",\")[0].split())\n",
    "    body = clean_xpath(tree.xpath(\"/html/body/div[4]/div/div[3]/div/div/div[3]/div[1]/text()\"))\n",
    "    news_from_source = clean_xpath(tree.xpath(\"/html/body/div[4]/div/div[3]/div/div/div[4]/div/a/text()\"))\n",
    "    news = (news_url,headline,body,author,time,date,news_from_source)\n",
    "    return news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temp = pd.read_csv('inshorts_new_url.csv')\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temp.news_url.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_news():\n",
    "    if os.path.isfile(myfile):\n",
    "        myfile = \"F:\\GitHub\\Indian_News_Grabber\\inshorts\\inshorts_new_url.csv\"\n",
    "        l = []\n",
    "        proxy = {\n",
    "            \"http\":\"http://45.64.11.1:8080\",\n",
    "            \"http\":\"http://125.62.213.161:83\",\n",
    "            \"http\":\"http://103.218.101.113:8080\",\n",
    "            \"http\":\"http://103.253.211.182:8080\",\n",
    "            \"http\":\"http://103.46.233.21:83\",\n",
    "            \"http\":\"http://103.46.233.27:82\",\n",
    "            \"http\":\"http://175.101.80.145:8080\",\n",
    "            \"http\":\"http://175.101.80.140:8080\",\n",
    "            \"http\":\"http://123.108.200.118:83\",\n",
    "            \"http\":\"http://103.26.56.30:8080\",\n",
    "            \"http\":\"http://103.226.3.233:8080\",\n",
    "            \"http\":\"http://103.41.99.130:8080\",\n",
    "            \"http\":\"http://103.224.48.17:8080\",\n",
    "            \"http\":\"http://103.209.64.19:6666\",\n",
    "            \"http\":\"http://103.14.235.26:8080\",\n",
    "        }\n",
    "        for i in range(len(temp)):\n",
    "            l.append(get_news(temp.news_url.iloc[i],proxy))\n",
    "        news_total = pd.DataFrame.from_records(l, columns=['url','headline','body','author','time','date','source'])\n",
    "        news_total.to_csv('news_inshorts.csv', index = False, mode = a)\n",
    "        news_total = pd.read_csv('news_inshorts.csv')\n",
    "        #news_total = news_total.drop(news_total.columns[[0]], axis=1)\n",
    "        if os.path.isfile(myfile):\n",
    "            os.remove(myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_news()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
